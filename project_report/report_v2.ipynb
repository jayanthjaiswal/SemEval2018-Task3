{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS289 Final Project: Irony Detection in English Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team: Jayanth, Sudharsan Krishnaswamy, Debleena Sengupta, Shadi Shahsavari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advent of social media like Twitter and Facebook has led to rise of people using more creative and figurative language use like Irony, Sarcasm, Hyperbole etc to catch the social network’s attention for more likes and retweets. Natural Language Processing Tasks on such social media datasets like Sentiment Analysis, Opinion Mining, Argument Analysis etc struggle to maintain high performance, when applied to Ironic texts. We try to tackle this hard problem of Irony Detection using new advances in Deep Learning technologies. We approach two specific tasks in our work based on SemEval 2018 dataset. The first task is to detect if a tweet is “ironic” or not (binary classification of 0 or 1). The second task is to identify between “ironic” and “non-ironic” tweets and then, place ironic tweets into one of four categories :\n",
    "- Verbal irony realized through a polarity contrast, \n",
    "- Verbal irony without such a polarity contrast (i.e., other verbal irony), \n",
    "- Situational irony,\n",
    "- Non-irony, which requires context for being ironic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemEval Dataset Preprocessing and Corpus Analysis with Visual Plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Implementations of traditional ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Model to Capture Linguistic Property of Irony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Algorithm Implementation and Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Implementation and Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the deep learning model, we explored a boosting implementation. The idea was to use the same word embedding features that were used in the DNN in teh boosting algorithm to see if we could achieve a letter performance. Below is the implementation of our boosting algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#preprocess data files that contain word_embedding features.\n",
    "#May need to change path based on where data is\n",
    "data_y_fp = \"./labels.txt\"\n",
    "directory = \"word_embeddings\"\n",
    "MAX_LENGTH = 310\n",
    "data_x = []\n",
    "data_y = []\n",
    "\n",
    "#go through labels file:\n",
    "with open(data_y_fp) as f:\n",
    "    for label in f:\n",
    "        label = int(label)\n",
    "        data_y.append(label)\n",
    "data_y = np.array(data_y)\n",
    "\n",
    "#go through the feature files. Each file has 25 features\n",
    "files = os.listdir(directory)\n",
    "os.chdir(directory)\n",
    "for filename in files:\n",
    "    example = []\n",
    "    name = filename.split(\".\")\n",
    "    file_num = int(name[0])\n",
    "    label = data_y[file_num-1]\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            tmp = line.split(\" \")\n",
    "            tmp = tmp[:len(tmp)-1]\n",
    "            tmp = map(float, tmp)\n",
    "            example = example + tmp\n",
    "    example = np.array(example)\n",
    "    if len(example)>MAX_LENGTH:\n",
    "        example = example[:MAX_LENGTH]\n",
    "    if len(example)<MAX_LENGTH:\n",
    "        example = np.pad(example, (0,MAX_LENGTH-len(example)), 'constant')\n",
    "    example = np.append(example, label)\n",
    "    data_x.append(example)\n",
    "data_x = np.array(data_x)\n",
    "X = data_x[:,0:MAX_LENGTH]\n",
    "Y = data_x[:,MAX_LENGTH]\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = XGBRegressor(max_depth=3) #gave 56.51%\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Accuracy: 58.33%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the implementation, we decided to use the XGBRegressor from the xgboost library. This is a classifier uses a logistic regression model to perform the binary classification task. Based on the history of the performance of boosting, we thought that with the proper feature selection, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis and Test Data Evaluation Submission on SemEval Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
